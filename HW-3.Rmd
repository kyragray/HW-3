---
title: "MATH 216 Homework 3"
author: "Kyra Gray"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    smooth_scroll: false
---

```{r, echo=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(readr)
library(lubridate)
library(Quandl)
library(knitr)
library(forcats)
```



## Admistrative:

Please indicate

* Who you collaborated with: Amanda Hotvedt, Katherine Hobbs
* Roughly how much time you spent on this HW so far: 6 hours 
* The URL of the RPubs published URL [here](http://rpubs.com/kyragray/219941).
* What gave you the most trouble:
* Any comments you have:




## Question 1:

We will use a logistic regression model to predict sex. Our metric to rate how well our
model performs will be:

$$
\frac{1}{n}\sum_{i=1}^{n}I(y_i = \widehat{y}_i)
$$

where $I(A)$ is the *indicator function* that is equal to 1 if condition $A$
holds, 0 otherwise. So

* Say user $i$ **is** female, then $y_i=1$
* Say we **predict** user $i$ is female, then $\widehat{y}_i=1$
* In this case $I(y_i =\widehat{y}_i)=1$. 

So what the above formula is reporting is the proportion of users' sex we
correctly predicted.

```{r, echo=FALSE, message=FALSE, cache=TRUE}
# Edit this code block at your own peril! cache is set to TRUE!
# To keep this exercise simple, let's remove the only 3 users (0.005% of users)
# who did not list a height, define the outcome variable, and add an ID variable
# to distinguish the users
profiles <- read_csv(file="profiles.csv") %>% 
  filter(!is.na(height)) %>% 
  mutate(is_female=ifelse(sex=='f', 1, 0)) %>% 
  tibble::rownames_to_column(var="id")
```


```{r, echo=TRUE, message=TRUE, warning=TRUE, fig.width=8, fig.height=4.5}
profiles <- profiles %>% 
mutate(income_level = 
  ifelse(income %in% -2:0, "No Response",
  ifelse(income %in% 0:20000, "Low Income",
  ifelse(income %in% 20001:70000, "Middle Income",
  ifelse(income %in% 70000:1000000, "High Income", " "))))) %>% 
  mutate(job_new = ifelse(is.na(job), "NA", job)) %>% 
  mutate(job_new = fct_recode(job_new, 
                            "not currently working" = "unemployed", 
                            "not currently working" = "student", 
                            "not currently working" = "retired", 
                            "no response" = "rather not say", 
                            "no response" = "NA",   
                            "entertainment" = "entertainment / media", 
                            "entertainment" = "artistic / musical / writer", 
                            "miscellaneous" = "military",
                            "miscellaneous" = "political / government", 
                            "miscellaneous" = "clerical / administrative", 
                            "miscellaneous" = "law / legal services", 
                            "miscellaneous" = "construction / craftsmanship", 
                            "miscellaneous" = "transportation", 
                            "miscellaneous" = "hospitality / travel")) %>% 
mutate(age_level = 
  ifelse(age %in% 18:19, "Under 20",
  ifelse(age %in% 20:29, "Twenties",
  ifelse(age %in% 30:39, "Thirties",
  ifelse(age %in% 40:49, "Forties", 
  ifelse(age %in% 50:59, "Fifties", 
  ifelse(age %in% 60:111, "60 and Over", " ")))))))

```


#### a)

Define:

* A *training* set `training` of 2997 users (5% of users). We will train the 
logistic regression model to predict gender using this data. Since we want to 
train the model to tell who is female and who is not, we use the outcome
variable `is_female`.
* A *test* set `test` of the remaining 56,946 users (95% of users). We will test
how good our trained model is using this data. So at first, we will pretend we
don't know the outcome variable `is_female`. We use the above model to make a
prediction of sex for all 56,946 test users, then we use the `is_female` outcome
to rate how well we performed.
* Be sure to incorporate all the insight your garnered in your EDA in HW-2.

```{r, echo=TRUE, message=TRUE, warning=TRUE, fig.width=8, fig.height=4.5}
set.seed(9)
training <- sample_n(profiles, 2997)
test <- profiles %>% 
  filter(!(id %in% training$id))
```



#### b)

Train the logistic regression model to predict sex. i.e. fit a logistic
regression model to the `training` data. Assign this model to an R object called
`predict_sex_model`, then rate how well the model performs on the `training` data.

```{r, echo=TRUE, message=TRUE, warning=TRUE, fig.width=8, fig.height=4.5}
predict_sex_model <- glm(is_female ~income_level + job_new + age_level, data = training, family = "binomial")

prediction_training <- predict(predict_sex_model, newdata=training, type="response")

training <- training %>% 
  mutate(phat=predict(predict_sex_model, newdata=training, type="response")) %>% 
  select(income_level, job_new, age_level, phat, is_female) %>% 
  mutate(predicted_correct=
        ifelse((phat>=.4023 & is_female==1) | (phat<.4023 & is_female==0), 1, 0)) 

training_correct <- training %>% 
  group_by(predicted_correct) %>% 
  summarise(n=n()) %>% 
  mutate(prop = n/sum(n)) 
knitr::kable(training_correct)
```



#### c)

Take `predict_sex_model` and apply it to the `test` data and make a prediction 
for each users' sex, then rate how well the model performs on the `test` data.

**Hint**: What do you think `predict(predict_sex_model, newdata=test,
type="response")` does? The help file is located in `?predict.glm`

```{r, echo=TRUE, message=TRUE, warning=TRUE, fig.width=8, fig.height=4.5}

prediction_test <- predict(predict_sex_model, newdata=test, type="response")

test <- test %>% 
  mutate(phat=predict(predict_sex_model, newdata=test, type="response")) %>% 
  select(income_level, job_new, age_level, phat, is_female) %>% 
  mutate(predicted_correct=
        ifelse((phat>=.4023 & is_female==1) | (phat<.4023 & is_female==0), 1, 0))  

test_correct <- test %>% 
  group_by(predicted_correct) %>% 
  summarise(n=n()) %>% 
  mutate(prop = n/sum(n)) 
knitr::kable(test_correct)  

```



#### d)

Did the model perform better on the `training` data or the `test` data? Why
do you think that is?

  Considering that the model was built on the training data, I hypothesized that the model would perform better on the training data. The results support the hypothesis but not as strongly as I would have guessed, the model using the training data predicts sex correctly 60% of the time and the model using the test data predicts sex correctly 58% of the time. 




## Question 2:

We want to compare the volatility of 

* [Bitcoin](https://www.quandl.com/data/BAVERAGE/USD) prices
* [Gold](https://www.quandl.com/data/BUNDESBANK/BBK01_WT5511) prices

Let our measure of volatility be the relative change from day-to-day in price. 
Let the reference currency be US dollars. Analyze these results and provide
insight to a foreign currency exchanger.

```{r, echo=TRUE, message=TRUE, warning=TRUE, fig.width=8, fig.height=4.5}
bitcoin <- Quandl("BAVERAGE/USD", api_key="HT-hvAhCykRB7qMy-oHD") %>% 
  tbl_df()
gold <- Quandl("BUNDESBANK/BBK01_WT5511", api_key="HT-hvAhCykRB7qMy-oHD") %>% 
  tbl_df()

bitcoin <- bitcoin %>% 
  rename(Avg = `24h Average`, Total_Volume=`Total Volume`) 
  
bitcoin$Avg_next_day <- lead(bitcoin$Avg, 1)

bitcoin <- bitcoin %>% 
  mutate(daily_change=(Avg_next_day-Avg))

gold_recent <- gold %>% 
  filter(Date %within% interval(ymd("2010-01-01"), ymd("2016-12-31")))

gold_recent$Value_next_day <- lead(gold_recent$Value, 1)

gold_recent <- gold_recent %>% 
  mutate(daily_change=(Value_next_day-Value))


 p <- ggplot() +
   geom_line(data=bitcoin, aes(x=Date, y=daily_change, color="Bitcoin")) +
   geom_line(data=gold_recent, aes(x=Date, y=daily_change, color="Gold")) +
   labs(title="Bitcoin Volatility compared to Gold", x="Date", y="Daily Average")
 p
```





## Question 3:

```{r, echo=FALSE, message=FALSE, cache=TRUE}
# Edit this code block at your own peril! cache is set to TRUE!
jukebox <- read_csv(file="reed_jukebox.csv")

# Clean certain artists' names:
sigur_ros <- "Sigur Ro\xfc\xbe\x99\x86\x94\xbc\xfc\xbe\x8c\x93\xa0\xbcs"
bjork <- "Bjo\xfc\xbe\x99\x86\x94\xbc\xfc\xbe\x8d\xa6\x98\xbcrk"
blue_oyster_cult <- "Blue O\xfc\xbe\x99\x86\x94\xbc\xfc\xbe\x8d\xa6\x98\xbcyster Cult"
husker_do <- "Hu\xfc\xbe\x99\x86\x94\xbc\xfc\xbe\x8d\xa6\x98\xbcsker Du\xfc\xbe\x99\x86\x94\xbc\xfc\xbe\x8d\xa6\x98\xbc"
bjork_brodsky <- "Bjo\xfc\xbe\x99\x86\x94\xbc\xfc\xbe\x8d\xa6\x98\xbcrk & Brodsky Quartet"
slagsmalsklubben <- "Slagsma\xfc\xbe\x99\x86\x94\xbc_lsklubben "
bjork_sugarcubes <- "Bjo\xfc\xbe\x99\x86\x94\xbc\xfc\xbe\x8d\xa6\x98\xbcrk (Sugarcubes)"

jukebox <- jukebox %>%
  mutate(
    artist = ifelse(artist == sigur_ros, "Sigor Ros", artist),
    artist = ifelse(artist == bjork, "Bjork", artist),
    artist = ifelse(artist == blue_oyster_cult, "Blue Oyster Cult", artist),
    artist = ifelse(artist == husker_do, "Husker Do", artist),
    artist = ifelse(artist == bjork_brodsky, "Bjork & Brodsky Quartet", artist),
    artist = ifelse(artist == slagsmalsklubben, "Slagsmalsklubben", artist),
    artist = ifelse(artist == bjork_sugarcubes, "Bjork (Sugarcubes)", artist)
  )
```


Using the Reed College jukebox data, what are the top 10 artists played during
the "graveyard shift" during the academic year? Define

* the "graveyard shift" as midnight to 8am
* the academic year as September through May (inclusive)

```{r, echo=TRUE, message=TRUE, warning=TRUE, fig.width=8, fig.height=4.5}
jukebox <- jukebox %>% 
  mutate(Date = parse_date_time(date_time, "a b d HMS Y")) %>% 
  mutate(Month=month(Date)) %>% 
  mutate(Hour=hour(Date))

graveyard <- jukebox %>% 
  filter(Month<=5 | Month>=9) %>% 
  filter(Hour>=24 | Hour<=8)

graveyard_artist <- graveyard %>% 
  group_by(artist) %>% 
  tally() %>% 
  ungroup(artist) %>% 
  arrange(desc(n))

graveyard_artist_top10 <- graveyard_artist %>%
  filter(n>1275)
  
knitr::kable(graveyard_artist_top10)
```





